1
00:00:00,580 --> 00:00:04,380
I hope that algorithm for incremental concept learning makes sense to you.

2
00:00:04,380 --> 00:00:07,310
Here is another way of visualization that algorithm.

3
00:00:07,310 --> 00:00:11,740
Imagine that an AI agent was given a positive example and the AI agent may

4
00:00:11,740 --> 00:00:15,530
come up with a concept definition that covers that positive example.

5
00:00:15,530 --> 00:00:19,600
Now let us suppose that the AI agent is given a negative example, and

6
00:00:19,600 --> 00:00:23,710
this negative example is covered by the current concept definition. Well in

7
00:00:23,710 --> 00:00:27,040
that case the current concept definition must be refined in such a way that

8
00:00:27,040 --> 00:00:31,780
the negative example is excluded, while still including the positive example. So

9
00:00:31,780 --> 00:00:36,460
you can visualize a new concept definition which includes the positive example,

10
00:00:36,460 --> 00:00:40,010
but excludes the negative example. Now let us suppose that the AI agent is given

11
00:00:40,010 --> 00:00:45,430
another positive example, in which case the AI agent must revise its definition

12
00:00:45,430 --> 00:00:50,330
of the concept so that the new positive example is also included so that's

13
00:00:50,330 --> 00:00:55,160
also covered. So we may revise this concept definition something like this. And

14
00:00:55,160 --> 00:00:59,650
we can repeat this exercise many times. Imagine there is a negative example and

15
00:00:59,650 --> 00:01:01,570
the current concept definition covers it.

16
00:01:01,570 --> 00:01:05,500
Well, we can refine it in such a way that a new negative example is excluded and

17
00:01:05,500 --> 00:01:09,790
so on. We can imagine going through several of these iterations of positive and

18
00:01:09,790 --> 00:01:14,820
negative examples. Eventually we'll get a concept definition that includes,

19
00:01:14,820 --> 00:01:20,010
that covers all the positive examples, and excludes all the negative examples.

20
00:01:20,010 --> 00:01:23,750
So again, the problem is the same. Given a small set of positive and

21
00:01:23,750 --> 00:01:27,500
negative examples, the number of dimensions in

22
00:01:27,500 --> 00:01:31,730
which the algorithm can do generalization and specialization is very large.

23
00:01:32,830 --> 00:01:37,968
How do, how do we constrain the learning in this complex learning space?

24
00:01:37,968 --> 00:01:41,512
That's where those [UNKNOWN] and background knowledge come in.

25
00:01:41,512 --> 00:01:45,940
The [UNKNOWN] guide the algorithm so that it revises the concept definition

26
00:01:45,940 --> 00:01:49,660
in an efficient manner and the background knowledge helps in that process.
