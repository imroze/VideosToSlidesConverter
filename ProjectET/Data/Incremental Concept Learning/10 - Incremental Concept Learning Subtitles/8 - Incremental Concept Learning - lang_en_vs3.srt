1
00:00:00,440 --> 00:00:04,260
Here is the basic algorithm for
incremental concept learning and

2
00:00:04,260 --> 00:00:07,660
David has created a visual
illustration of this algorithm.

3
00:00:07,660 --> 00:00:11,890
We're given an example and we're also
told whether it's a positive example or

4
00:00:11,890 --> 00:00:12,720
a negative example.

5
00:00:13,775 --> 00:00:15,338
If this is a positive example,

6
00:00:15,338 --> 00:00:19,600
then the algorithm comes to the left
branch of this particular tree.

7
00:00:19,600 --> 00:00:23,090
And it asks does the current
definition of the concept

8
00:00:23,090 --> 00:00:24,880
cover this positive example?

9
00:00:24,880 --> 00:00:26,730
We want to cover positive examples.

10
00:00:28,000 --> 00:00:31,360
If it already covers the positive
example, we don't have to do anything.

11
00:00:31,360 --> 00:00:34,580
We don't have to devise a current
definition of the concept.

12
00:00:34,580 --> 00:00:38,420
On the other hand, if the current
definition of the concept does not

13
00:00:38,420 --> 00:00:41,820
cover the positive example then
we must revise it in some way so

14
00:00:41,820 --> 00:00:44,460
that it does, so we will generalize it.

15
00:00:44,460 --> 00:00:45,745
On the other half of the tree,

16
00:00:45,745 --> 00:00:50,470
if this example is not a positive
instance of the example, then

17
00:00:50,470 --> 00:00:54,230
we can ask ourselves does the current
definition of the concept cover it?

18
00:00:55,580 --> 00:00:57,900
If it doesn't cover it,
it shouldn't cover it.

19
00:00:57,900 --> 00:01:00,910
And if it doesn't cover it,
then we don't have to do anything.

20
00:01:00,910 --> 00:01:04,800
On the other hand, if the example
is a negative instance and

21
00:01:04,800 --> 00:01:06,910
if current definition does cover it,

22
00:01:06,910 --> 00:01:10,560
then we want to define our current
definition to rule it out.

23
00:01:10,560 --> 00:01:13,170
So we'll specialize in
a current definition.

24
00:01:13,170 --> 00:01:16,850
&gt;&gt; So, oftentimes, we see children
committing overgeneralization or

25
00:01:16,850 --> 00:01:18,340
overspecialization.

26
00:01:18,340 --> 00:01:21,200
So, to take an example of this,
we can imagine a child

27
00:01:21,200 --> 00:01:23,720
that has a concept of a cat,
but the cat has to be black.

28
00:01:24,870 --> 00:01:28,150
The child has only ever been around
black cats, so part of their definition,

29
00:01:28,150 --> 00:01:30,660
part of their concept of
the cat is that cats are black.

30
00:01:31,730 --> 00:01:33,890
When she goes over to
her friend's house,

31
00:01:33,890 --> 00:01:37,140
Is introduced to her friend's cat,
and her friend's cat is orange.

32
00:01:37,140 --> 00:01:40,550
Right now, she's told that this
is an example of a cat, but

33
00:01:40,550 --> 00:01:43,020
it does not fit her current
definition of a cat so

34
00:01:43,020 --> 00:01:46,740
she needs to generalize her definition
that cats can be different colors.

35
00:01:46,740 --> 00:01:51,430
Similarly, we can imagine another child
that has only ever been exposed to dogs.

36
00:01:51,430 --> 00:01:55,610
Thus the child's concept of a dog is
that a dog is anything that is furry,

37
00:01:55,610 --> 00:01:58,170
has four legs and that we keep as a pet.

38
00:01:58,170 --> 00:02:00,040
This child goes over to
the same friend's house and

39
00:02:00,040 --> 00:02:02,110
is introduced to this orange cat.

40
00:02:02,110 --> 00:02:04,810
And right now, that orange cat
fits his definition of a dog.

41
00:02:04,810 --> 00:02:06,860
It's furry, it has four legs,
and they keep it as a pet.

42
00:02:06,860 --> 00:02:09,320
But he's told that
this cat is not a dog.

43
00:02:09,320 --> 00:02:14,790
So he needs to specialize his concept
of a dog to exclude this cat.

44
00:02:14,790 --> 00:02:15,470
&gt;&gt; That's good, David.

45
00:02:15,470 --> 00:02:17,890
It connects things with
our everyday lives.
